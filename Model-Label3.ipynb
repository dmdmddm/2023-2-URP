{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41980,"status":"ok","timestamp":1700909580236,"user":{"displayName":"표솔빈","userId":"04100473901833453355"},"user_tz":-540},"id":"Id0qJ-e2vLcR","outputId":"f1077ea9-5c8d-4a25-d371-793c9bfcc770"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["## Resnet152\n"],"metadata":{"id":"iGu5Hj2PJIPd"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CkdJjtJ0yxGh","executionInfo":{"status":"ok","timestamp":1700906899684,"user_tz":-540,"elapsed":1025621,"user":{"displayName":"표솔빈","userId":"04100473901833453355"}},"outputId":"3fe45433-d19e-4864-ac83-3ed4149db4b9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n","234545216/234545216 [==============================] - 7s 0us/step\n","Found 1502 images belonging to 2 classes.\n","Found 464 images belonging to 2 classes.\n","Epoch 1/20\n","94/94 [==============================] - 672s 6s/step - loss: 5.5610 - accuracy: 0.5180 - val_loss: 5.4683 - val_accuracy: 0.3599 - lr: 0.0000e+00\n","Epoch 2/20\n","94/94 [==============================] - 17s 177ms/step - loss: 5.1078 - accuracy: 0.7250 - val_loss: 5.2761 - val_accuracy: 0.6013 - lr: 2.0000e-05\n","Epoch 3/20\n","94/94 [==============================] - 17s 177ms/step - loss: 4.5655 - accuracy: 0.9201 - val_loss: 5.2041 - val_accuracy: 0.6422 - lr: 4.0000e-05\n","Epoch 4/20\n","94/94 [==============================] - 17s 177ms/step - loss: 4.2267 - accuracy: 0.9621 - val_loss: 5.1478 - val_accuracy: 0.6638 - lr: 6.0000e-05\n","Epoch 5/20\n","94/94 [==============================] - 17s 177ms/step - loss: 3.9414 - accuracy: 0.9614 - val_loss: 4.3736 - val_accuracy: 0.7457 - lr: 8.0000e-05\n","Epoch 6/20\n","94/94 [==============================] - 17s 177ms/step - loss: 3.5700 - accuracy: 0.9794 - val_loss: 4.0856 - val_accuracy: 0.7478 - lr: 1.0000e-04\n","Epoch 7/20\n","94/94 [==============================] - 17s 177ms/step - loss: 3.2866 - accuracy: 0.9814 - val_loss: 3.9381 - val_accuracy: 0.7177 - lr: 9.1405e-05\n","Epoch 8/20\n","94/94 [==============================] - 17s 177ms/step - loss: 3.0690 - accuracy: 0.9874 - val_loss: 3.3501 - val_accuracy: 0.8276 - lr: 6.8905e-05\n","Epoch 9/20\n","94/94 [==============================] - 17s 177ms/step - loss: 2.9217 - accuracy: 0.9940 - val_loss: 3.4504 - val_accuracy: 0.7500 - lr: 4.1093e-05\n","Epoch 10/20\n","94/94 [==============================] - 17s 177ms/step - loss: 2.8620 - accuracy: 0.9880 - val_loss: 3.4561 - val_accuracy: 0.7522 - lr: 1.8594e-05\n","Epoch 11/20\n","94/94 [==============================] - 17s 177ms/step - loss: 2.8222 - accuracy: 0.9927 - val_loss: 3.3271 - val_accuracy: 0.7694 - lr: 1.0000e-05\n","Epoch 12/20\n","94/94 [==============================] - 17s 177ms/step - loss: 2.7743 - accuracy: 0.9967 - val_loss: 3.2316 - val_accuracy: 0.7888 - lr: 1.8594e-05\n","Epoch 13/20\n","94/94 [==============================] - 17s 177ms/step - loss: 2.6997 - accuracy: 0.9953 - val_loss: 3.1551 - val_accuracy: 0.7802 - lr: 4.1095e-05\n","Epoch 14/20\n","94/94 [==============================] - 17s 177ms/step - loss: 2.5756 - accuracy: 0.9927 - val_loss: 3.0650 - val_accuracy: 0.7845 - lr: 6.8908e-05\n","Epoch 15/20\n","94/94 [==============================] - 17s 177ms/step - loss: 2.4153 - accuracy: 0.9847 - val_loss: 3.0433 - val_accuracy: 0.7026 - lr: 9.1408e-05\n","Epoch 16/20\n","94/94 [==============================] - 17s 177ms/step - loss: 2.2529 - accuracy: 0.9747 - val_loss: 3.2470 - val_accuracy: 0.6121 - lr: 1.0000e-04\n","Epoch 17/20\n","94/94 [==============================] - 17s 177ms/step - loss: 2.0678 - accuracy: 0.9780 - val_loss: 2.9655 - val_accuracy: 0.6875 - lr: 9.1402e-05\n","Epoch 18/20\n","94/94 [==============================] - 17s 177ms/step - loss: 1.9165 - accuracy: 0.9854 - val_loss: 2.1657 - val_accuracy: 0.8470 - lr: 6.8900e-05\n","Epoch 19/20\n","94/94 [==============================] - 17s 177ms/step - loss: 1.8144 - accuracy: 0.9900 - val_loss: 2.1392 - val_accuracy: 0.8362 - lr: 4.1089e-05\n","Epoch 20/20\n","94/94 [==============================] - 17s 177ms/step - loss: 1.7494 - accuracy: 0.9967 - val_loss: 2.1222 - val_accuracy: 0.8362 - lr: 1.8592e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Average Validation Accuracy: 0.7226293101906777\n"]}],"source":["from keras.applications.densenet import DenseNet201\n","from keras.models import Model\n","from keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping, LearningRateScheduler\n","import math\n","import numpy as np\n","from keras.applications.resnet_v2 import ResNet152V2\n","\n","# ResNet152 모델 로드 (최상위 층 제외)\n","base_model = ResNet152V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","\n","# 모든 층을 훈련 가능하게 설정\n","for layer in base_model.layers:\n","    layer.trainable = True\n","\n","# 새로운 분류기 층 추가\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","x = Dense(256, activation='relu', kernel_regularizer='l2')(x)\n","x = BatchNormalization()(x)\n","x = Dropout(0.5)(x)  # 드롭아웃 비율 조정\n","predictions = Dense(1, activation='sigmoid')(x)\n","\n","# 새로운 모델 정의\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","# 옵티마이저 설정 (Adam 사용)\n","optimizer = Adam(learning_rate=0.0001)\n","\n","# 모델 컴파일\n","model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# 데이터 증강 없이 이미지 크기만 조정하는 ImageDataGenerator 설정\n","train_datagen = ImageDataGenerator(rescale=1./255)\n","validation_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# 데이터셋 로드 및 설정\n","train_generator = train_datagen.flow_from_directory(\n","    '/content/drive/MyDrive/DRUNK_DATA/LAYER3_TRAIN',\n","    target_size=(224, 224),\n","    batch_size=16,\n","    class_mode='binary')\n","\n","validation_generator = validation_datagen.flow_from_directory(\n","    '/content/drive/MyDrive/DRUNK_DATA/LAYER3_VALID',\n","    target_size=(224, 224),\n","    batch_size=16,\n","    class_mode='binary')\n","\n","# 코사인 니일링 웜업 스케줄러 함수 정의\n","def cosine_annealing_warmup(epoch, max_epoch=20, base_lr=0.0001, min_lr=0.00001):\n","    if epoch < 5:  # 웜업 기간 설정 (예: 처음 5 에포크)\n","        return base_lr * epoch / 5\n","    else:\n","        return min_lr + (base_lr - min_lr) * (1 + math.cos(math.pi * (epoch - 5) / (max_epoch - 5))) / 2\n","\n","# 코사인 니일링 웜업 스케줄러 콜백 생성\n","cosine_lr_scheduler = LearningRateScheduler(cosine_annealing_warmup)\n","\n","# 조기 중단 콜백 설정 (정확도 기반)\n","early_stopping = EarlyStopping(monitor='val_accuracy', mode='max', patience=10)\n","\n","# steps_per_epoch와 validation_steps 계산\n","steps_per_epoch = train_generator.samples // train_generator.batch_size\n","if train_generator.samples % train_generator.batch_size > 0:\n","    steps_per_epoch += 1\n","\n","validation_steps = validation_generator.samples // validation_generator.batch_size\n","if validation_generator.samples % validation_generator.batch_size > 0:\n","    validation_steps += 1\n","\n","# 모델 학습\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch=steps_per_epoch,\n","    epochs=20,\n","    validation_data=validation_generator,\n","    validation_steps=validation_steps,\n","    callbacks=[cosine_lr_scheduler, early_stopping])\n","\n","# 모델 저장\n","model.save('Resnet152_drunk_or_sober.h5')\n","\n","# 각 epoch에서의 검증 정확도(val_accuracy) 리스트 가져오기\n","val_accuracies = history.history['val_accuracy']\n","\n","# 평균 검증 정확도 계산\n","average_val_accuracy = np.mean(val_accuracies)\n","\n","print(\"Average Validation Accuracy:\", average_val_accuracy)"]},{"cell_type":"markdown","source":["## Mobilenet_V3"],"metadata":{"id":"XTpN6sI1Mkz9"}},{"cell_type":"code","source":["from keras.applications.densenet import DenseNet201\n","from keras.models import Model\n","from keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping, LearningRateScheduler\n","import math\n","import numpy as np\n","from keras.applications import MobileNetV3Large\n","\n","# MobileNetV3Large 모델 로드 (최상위 층 제외)\n","base_model = MobileNetV3Large(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","\n","\n","# 모든 층을 훈련 가능하게 설정\n","for layer in base_model.layers:\n","    layer.trainable = True\n","\n","# 새로운 분류기 층 추가\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","x = Dense(256, activation='relu', kernel_regularizer='l2')(x)\n","x = BatchNormalization()(x)\n","x = Dropout(0.5)(x)  # 드롭아웃 비율 조정\n","predictions = Dense(1, activation='sigmoid')(x)\n","\n","# 새로운 모델 정의\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","# 옵티마이저 설정 (Adam 사용)\n","optimizer = Adam(learning_rate=0.0001)\n","\n","# 모델 컴파일\n","model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# 데이터 증강 없이 이미지 크기만 조정하는 ImageDataGenerator 설정\n","train_datagen = ImageDataGenerator(rescale=1./255)\n","validation_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# 데이터셋 로드 및 설정\n","train_generator = train_datagen.flow_from_directory(\n","    '/content/drive/MyDrive/DRUNK_DATA/LAYER3_TRAIN',\n","    target_size=(224, 224),\n","    batch_size=16,\n","    class_mode='binary')\n","\n","validation_generator = validation_datagen.flow_from_directory(\n","    '/content/drive/MyDrive/DRUNK_DATA/LAYER3_VALID',\n","    target_size=(224, 224),\n","    batch_size=16,\n","    class_mode='binary')\n","\n","# 코사인 니일링 웜업 스케줄러 함수 정의\n","def cosine_annealing_warmup(epoch, max_epoch=20, base_lr=0.0001, min_lr=0.00001):\n","    if epoch < 5:  # 웜업 기간 설정 (예: 처음 5 에포크)\n","        return base_lr * epoch / 5\n","    else:\n","        return min_lr + (base_lr - min_lr) * (1 + math.cos(math.pi * (epoch - 5) / (max_epoch - 5))) / 2\n","\n","# 코사인 니일링 웜업 스케줄러 콜백 생성\n","cosine_lr_scheduler = LearningRateScheduler(cosine_annealing_warmup)\n","\n","# 조기 중단 콜백 설정 (정확도 기반)\n","early_stopping = EarlyStopping(monitor='val_accuracy', mode='max', patience=10)\n","\n","# steps_per_epoch와 validation_steps 계산\n","steps_per_epoch = train_generator.samples // train_generator.batch_size\n","if train_generator.samples % train_generator.batch_size > 0:\n","    steps_per_epoch += 1\n","\n","validation_steps = validation_generator.samples // validation_generator.batch_size\n","if validation_generator.samples % validation_generator.batch_size > 0:\n","    validation_steps += 1\n","\n","# 모델 학습\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch=steps_per_epoch,\n","    epochs=20,\n","    validation_data=validation_generator,\n","    validation_steps=validation_steps,\n","    callbacks=[cosine_lr_scheduler, early_stopping])\n","\n","# 모델 저장\n","model.save('mobilenet_v3_drunk_or_sober.h5')\n","\n","# 각 epoch에서의 검증 정확도(val_accuracy) 리스트 가져오기\n","val_accuracies = history.history['val_accuracy']\n","\n","# 평균 검증 정확도 계산\n","average_val_accuracy = np.mean(val_accuracies)\n","\n","print(\"Average Validation Accuracy:\", average_val_accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aXwTAMCgMsSp","executionInfo":{"status":"ok","timestamp":1700907043354,"user_tz":-540,"elapsed":92180,"user":{"displayName":"표솔빈","userId":"04100473901833453355"}},"outputId":"0fe96b91-d332-466f-c3be-3a57ed91d723"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_large_224_1.0_float_no_top_v2.h5\n","12683000/12683000 [==============================] - 1s 0us/step\n","Found 1502 images belonging to 2 classes.\n","Found 464 images belonging to 2 classes.\n","Epoch 1/20\n","94/94 [==============================] - 33s 77ms/step - loss: 5.0946 - accuracy: 0.5120 - val_loss: 4.7790 - val_accuracy: 0.5000 - lr: 0.0000e+00\n","Epoch 2/20\n","94/94 [==============================] - 5s 58ms/step - loss: 4.8003 - accuracy: 0.6418 - val_loss: 4.7491 - val_accuracy: 0.5000 - lr: 2.0000e-05\n","Epoch 3/20\n","94/94 [==============================] - 5s 57ms/step - loss: 4.4643 - accuracy: 0.7770 - val_loss: 4.6929 - val_accuracy: 0.5000 - lr: 4.0000e-05\n","Epoch 4/20\n","94/94 [==============================] - 6s 58ms/step - loss: 4.1687 - accuracy: 0.8748 - val_loss: 4.6141 - val_accuracy: 0.5000 - lr: 6.0000e-05\n","Epoch 5/20\n","94/94 [==============================] - 6s 59ms/step - loss: 3.9128 - accuracy: 0.9434 - val_loss: 4.5401 - val_accuracy: 0.5000 - lr: 8.0000e-05\n","Epoch 6/20\n","94/94 [==============================] - 5s 57ms/step - loss: 3.7357 - accuracy: 0.9487 - val_loss: 4.4249 - val_accuracy: 0.5000 - lr: 1.0000e-04\n","Epoch 7/20\n","94/94 [==============================] - 6s 58ms/step - loss: 3.5011 - accuracy: 0.9720 - val_loss: 4.2752 - val_accuracy: 0.4677 - lr: 9.1405e-05\n","Epoch 8/20\n","94/94 [==============================] - 5s 57ms/step - loss: 3.3665 - accuracy: 0.9727 - val_loss: 4.0891 - val_accuracy: 0.3190 - lr: 6.8905e-05\n","Epoch 9/20\n","94/94 [==============================] - 5s 57ms/step - loss: 3.2432 - accuracy: 0.9907 - val_loss: 3.9389 - val_accuracy: 0.3039 - lr: 4.1093e-05\n","Epoch 10/20\n","94/94 [==============================] - 6s 58ms/step - loss: 3.1952 - accuracy: 0.9874 - val_loss: 3.8858 - val_accuracy: 0.4375 - lr: 1.8594e-05\n","Epoch 11/20\n","94/94 [==============================] - 5s 57ms/step - loss: 3.1743 - accuracy: 0.9820 - val_loss: 3.9247 - val_accuracy: 0.4957 - lr: 1.0000e-05\n","Average Validation Accuracy: 0.456700628454035\n"]}]},{"cell_type":"markdown","source":["## Inception_V3"],"metadata":{"id":"KPt7gs_qOXPK"}},{"cell_type":"code","source":["from keras.applications.inception_v3 import InceptionV3\n","from keras.models import Model\n","from keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping, LearningRateScheduler\n","import math\n","import numpy as np\n","\n","# InceptionV3 모델 로드 (최상위 층 제외)\n","base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))  # InceptionV3는 299x299 입력을 사용\n","\n","# 모든 층을 훈련 가능하게 설정\n","for layer in base_model.layers:\n","    layer.trainable = True\n","\n","# 새로운 분류기 층 추가\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","x = Dense(256, activation='relu')(x)  # kernel_regularizer는 필요에 따라 추가\n","x = BatchNormalization()(x)\n","x = Dropout(0.5)(x)\n","predictions = Dense(1, activation='sigmoid')(x)\n","\n","# 새로운 모델 정의\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","# 옵티마이저 설정 (Adam 사용)\n","optimizer = Adam(learning_rate=0.0001)\n","\n","# 모델 컴파일\n","model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# 데이터 증강 없이 이미지 크기만 조정하는 ImageDataGenerator 설정\n","train_datagen = ImageDataGenerator(rescale=1./255)\n","validation_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# 데이터셋 로드 및 설정\n","train_generator = train_datagen.flow_from_directory(\n","    '/content/drive/MyDrive/DRUNK_DATA/LAYER3_TRAIN',\n","    target_size=(299, 299),  # InceptionV3에 맞게 이미지 크기 조정\n","    batch_size=16,\n","    class_mode='binary')\n","\n","validation_generator = validation_datagen.flow_from_directory(\n","    '/content/drive/MyDrive/DRUNK_DATA/LAYER3_VALID',\n","    target_size=(299, 299),  # InceptionV3에 맞게 이미지 크기 조정\n","    batch_size=16,\n","    class_mode='binary')\n","\n","# 코사인 니일링 웜업 스케줄러 함수 정의\n","def cosine_annealing_warmup(epoch, max_epoch=20, base_lr=0.0001, min_lr=0.00001):\n","    if epoch < 5:  # 웜업 기간 설정 (예: 처음 5 에포크)\n","        return base_lr * epoch / 5\n","    else:\n","        return min_lr + (base_lr - min_lr) * (1 + math.cos(math.pi * (epoch - 5) / (max_epoch - 5))) / 2\n","\n","# 코사인 니일링 웜업 스케줄러 콜백 생성\n","cosine_lr_scheduler = LearningRateScheduler(cosine_annealing_warmup)\n","\n","# 조기 중단 콜백 설정 (정확도 기반)\n","early_stopping = EarlyStopping(monitor='val_accuracy', mode='max', patience=10)\n","\n","# steps_per_epoch와 validation_steps 계산\n","steps_per_epoch = train_generator.samples // train_generator.batch_size\n","if train_generator.samples % train_generator.batch_size > 0:\n","    steps_per_epoch += 1\n","\n","validation_steps = validation_generator.samples // validation_generator.batch_size\n","if validation_generator.samples % validation_generator.batch_size > 0:\n","    validation_steps += 1\n","\n","# 모델 학습\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch=steps_per_epoch,\n","    epochs=20,\n","    validation_data=validation_generator,\n","    validation_steps=validation_steps,\n","    callbacks=[cosine_lr_scheduler, early_stopping])\n","\n","# 모델 저장\n","model.save('InceptionV3_drunk_or_sober.h5')\n","\n","# 각 epoch에서의 검증 정확도(val_accuracy) 리스트 가져오기\n","val_accuracies = history.history['val_accuracy']\n","\n","# 평균 검증 정확도 계산\n","average_val_accuracy = np.mean(val_accuracies)\n","\n","print(\"Average Validation Accuracy:\", average_val_accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RL2qL04YObOy","executionInfo":{"status":"ok","timestamp":1700907433846,"user_tz":-540,"elapsed":240925,"user":{"displayName":"표솔빈","userId":"04100473901833453355"}},"outputId":"3e441c64-29b0-4739-85d2-2f82e721493b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","87910968/87910968 [==============================] - 3s 0us/step\n","Found 1502 images belonging to 2 classes.\n","Found 464 images belonging to 2 classes.\n","Epoch 1/20\n","94/94 [==============================] - 43s 147ms/step - loss: 1.1115 - accuracy: 0.4561 - val_loss: 0.7023 - val_accuracy: 0.5194 - lr: 0.0000e+00\n","Epoch 2/20\n","94/94 [==============================] - 10s 106ms/step - loss: 0.5949 - accuracy: 0.7250 - val_loss: 0.6722 - val_accuracy: 0.5970 - lr: 2.0000e-05\n","Epoch 3/20\n","94/94 [==============================] - 10s 106ms/step - loss: 0.2351 - accuracy: 0.9041 - val_loss: 0.5681 - val_accuracy: 0.6746 - lr: 4.0000e-05\n","Epoch 4/20\n","94/94 [==============================] - 10s 106ms/step - loss: 0.1095 - accuracy: 0.9587 - val_loss: 0.6693 - val_accuracy: 0.7004 - lr: 6.0000e-05\n","Epoch 5/20\n","94/94 [==============================] - 10s 106ms/step - loss: 0.0824 - accuracy: 0.9734 - val_loss: 0.3340 - val_accuracy: 0.8448 - lr: 8.0000e-05\n","Epoch 6/20\n","94/94 [==============================] - 10s 108ms/step - loss: 0.0367 - accuracy: 0.9907 - val_loss: 0.5537 - val_accuracy: 0.7802 - lr: 1.0000e-04\n","Epoch 7/20\n","94/94 [==============================] - 10s 107ms/step - loss: 0.0313 - accuracy: 0.9867 - val_loss: 0.5708 - val_accuracy: 0.7478 - lr: 9.1405e-05\n","Epoch 8/20\n","94/94 [==============================] - 10s 107ms/step - loss: 0.0429 - accuracy: 0.9887 - val_loss: 0.2794 - val_accuracy: 0.9095 - lr: 6.8905e-05\n","Epoch 9/20\n","94/94 [==============================] - 10s 106ms/step - loss: 0.0348 - accuracy: 0.9834 - val_loss: 0.7191 - val_accuracy: 0.7371 - lr: 4.1093e-05\n","Epoch 10/20\n","94/94 [==============================] - 10s 106ms/step - loss: 0.0154 - accuracy: 0.9933 - val_loss: 0.5762 - val_accuracy: 0.7780 - lr: 1.8594e-05\n","Epoch 11/20\n","94/94 [==============================] - 10s 107ms/step - loss: 0.0166 - accuracy: 0.9953 - val_loss: 0.5277 - val_accuracy: 0.7953 - lr: 1.0000e-05\n","Epoch 12/20\n","94/94 [==============================] - 10s 107ms/step - loss: 0.0136 - accuracy: 0.9980 - val_loss: 0.4600 - val_accuracy: 0.8233 - lr: 1.8594e-05\n","Epoch 13/20\n","94/94 [==============================] - 10s 106ms/step - loss: 0.0084 - accuracy: 0.9980 - val_loss: 0.3664 - val_accuracy: 0.8578 - lr: 4.1095e-05\n","Epoch 14/20\n","94/94 [==============================] - 10s 106ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.3476 - val_accuracy: 0.8685 - lr: 6.8908e-05\n","Epoch 15/20\n","94/94 [==============================] - 10s 106ms/step - loss: 0.0343 - accuracy: 0.9860 - val_loss: 0.2030 - val_accuracy: 0.9095 - lr: 9.1408e-05\n","Epoch 16/20\n","94/94 [==============================] - 10s 107ms/step - loss: 0.0314 - accuracy: 0.9887 - val_loss: 0.6685 - val_accuracy: 0.8017 - lr: 1.0000e-04\n","Epoch 17/20\n","94/94 [==============================] - 10s 106ms/step - loss: 0.0491 - accuracy: 0.9807 - val_loss: 0.4203 - val_accuracy: 0.8578 - lr: 9.1402e-05\n","Epoch 18/20\n","94/94 [==============================] - 10s 106ms/step - loss: 0.0472 - accuracy: 0.9827 - val_loss: 0.3390 - val_accuracy: 0.9224 - lr: 6.8900e-05\n","Epoch 19/20\n","94/94 [==============================] - 10s 106ms/step - loss: 0.0329 - accuracy: 0.9887 - val_loss: 0.3958 - val_accuracy: 0.8815 - lr: 4.1089e-05\n","Epoch 20/20\n","94/94 [==============================] - 10s 106ms/step - loss: 0.0123 - accuracy: 0.9980 - val_loss: 0.2402 - val_accuracy: 0.9246 - lr: 1.8592e-05\n"]}]},{"cell_type":"markdown","source":["## DenseNet201"],"metadata":{"id":"8J2GsZsZTvvQ"}},{"cell_type":"code","source":["from keras.applications.densenet import DenseNet201\n","from keras.models import Model\n","from keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping, LearningRateScheduler\n","import math\n","import numpy as np\n","\n","# DenseNet201 모델 로드 (최상위 층 제외)\n","base_model = DenseNet201(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","\n","# 모든 층을 훈련 가능하게 설정\n","for layer in base_model.layers:\n","    layer.trainable = True\n","\n","# 새로운 분류기 층 추가\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","x = Dense(256, activation='relu', kernel_regularizer='l2')(x)\n","x = BatchNormalization()(x)\n","x = Dropout(0.5)(x)  # 드롭아웃 비율 조정\n","predictions = Dense(1, activation='sigmoid')(x)\n","\n","# 새로운 모델 정의\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","# 옵티마이저 설정 (Adam 사용)\n","optimizer = Adam(learning_rate=0.0001)\n","\n","# 모델 컴파일\n","model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# 데이터 증강 없이 이미지 크기만 조정하는 ImageDataGenerator 설정\n","train_datagen = ImageDataGenerator(rescale=1./255)\n","validation_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# 데이터셋 로드 및 설정\n","train_generator = train_datagen.flow_from_directory(\n","    '/content/drive/MyDrive/DRUNK_DATA/LAYER3_TRAIN',\n","    target_size=(224, 224),\n","    batch_size=16,\n","    class_mode='binary')\n","\n","validation_generator = validation_datagen.flow_from_directory(\n","    '/content/drive/MyDrive/DRUNK_DATA/LAYER3_VALID',\n","    target_size=(224, 224),\n","    batch_size=16,\n","    class_mode='binary')\n","\n","# 코사인 니일링 웜업 스케줄러 함수 정의\n","def cosine_annealing_warmup(epoch, max_epoch=20, base_lr=0.0001, min_lr=0.00001):\n","    if epoch < 5:  # 웜업 기간 설정 (예: 처음 5 에포크)\n","        return base_lr * epoch / 5\n","    else:\n","        return min_lr + (base_lr - min_lr) * (1 + math.cos(math.pi * (epoch - 5) / (max_epoch - 5))) / 2\n","\n","# 코사인 니일링 웜업 스케줄러 콜백 생성\n","cosine_lr_scheduler = LearningRateScheduler(cosine_annealing_warmup)\n","\n","# 조기 중단 콜백 설정 (정확도 기반)\n","early_stopping = EarlyStopping(monitor='val_accuracy', mode='max', patience=10)\n","\n","# steps_per_epoch와 validation_steps 계산\n","steps_per_epoch = train_generator.samples // train_generator.batch_size\n","if train_generator.samples % train_generator.batch_size > 0:\n","    steps_per_epoch += 1\n","\n","validation_steps = validation_generator.samples // validation_generator.batch_size\n","if validation_generator.samples % validation_generator.batch_size > 0:\n","    validation_steps += 1\n","\n","# 모델 학습\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch=steps_per_epoch,\n","    epochs=20,\n","    validation_data=validation_generator,\n","    validation_steps=validation_steps,\n","    callbacks=[cosine_lr_scheduler, early_stopping])\n","\n","# 모델 저장\n","model.save('DenseNet201_drunk_or_sober.h5')\n","\n","# 각 epoch에서의 검증 정확도(val_accuracy) 리스트 가져오기\n","val_accuracies = history.history['val_accuracy']\n","\n","# 평균 검증 정확도 계산\n","average_val_accuracy = np.mean(val_accuracies)\n","\n","print(\"Average Validation Accuracy:\", average_val_accuracy)"],"metadata":{"id":"EzHk6W2APcWR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700907972288,"user_tz":-540,"elapsed":394554,"user":{"displayName":"표솔빈","userId":"04100473901833453355"}},"outputId":"8d3bae96-f28b-4482-b163-2bb17c9882b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1502 images belonging to 2 classes.\n","Found 464 images belonging to 2 classes.\n","Epoch 1/20\n","94/94 [==============================] - 114s 210ms/step - loss: 5.5980 - accuracy: 0.4820 - val_loss: 5.2205 - val_accuracy: 0.5259 - lr: 0.0000e+00\n","Epoch 2/20\n","94/94 [==============================] - 14s 152ms/step - loss: 4.9139 - accuracy: 0.7523 - val_loss: 5.3752 - val_accuracy: 0.4957 - lr: 2.0000e-05\n","Epoch 3/20\n","94/94 [==============================] - 14s 152ms/step - loss: 4.1909 - accuracy: 0.9254 - val_loss: 5.6805 - val_accuracy: 0.5022 - lr: 4.0000e-05\n","Epoch 4/20\n","94/94 [==============================] - 14s 152ms/step - loss: 3.5883 - accuracy: 0.9727 - val_loss: 5.9611 - val_accuracy: 0.5043 - lr: 6.0000e-05\n","Epoch 5/20\n","94/94 [==============================] - 14s 152ms/step - loss: 3.0190 - accuracy: 0.9740 - val_loss: 4.6141 - val_accuracy: 0.5582 - lr: 8.0000e-05\n","Epoch 6/20\n","94/94 [==============================] - 14s 151ms/step - loss: 2.5157 - accuracy: 0.9814 - val_loss: 3.3576 - val_accuracy: 0.6552 - lr: 1.0000e-04\n","Epoch 7/20\n","94/94 [==============================] - 14s 153ms/step - loss: 2.1354 - accuracy: 0.9847 - val_loss: 4.3124 - val_accuracy: 0.5733 - lr: 9.1405e-05\n","Epoch 8/20\n","94/94 [==============================] - 14s 152ms/step - loss: 1.9109 - accuracy: 0.9874 - val_loss: 3.5709 - val_accuracy: 0.5711 - lr: 6.8905e-05\n","Epoch 9/20\n","94/94 [==============================] - 14s 153ms/step - loss: 1.7712 - accuracy: 0.9973 - val_loss: 2.0933 - val_accuracy: 0.8254 - lr: 4.1093e-05\n","Epoch 10/20\n","94/94 [==============================] - 14s 151ms/step - loss: 1.7115 - accuracy: 0.9987 - val_loss: 1.9554 - val_accuracy: 0.8707 - lr: 1.8594e-05\n","Epoch 11/20\n","94/94 [==============================] - 14s 152ms/step - loss: 1.6898 - accuracy: 0.9967 - val_loss: 1.8571 - val_accuracy: 0.9224 - lr: 1.0000e-05\n","Epoch 12/20\n","94/94 [==============================] - 14s 152ms/step - loss: 1.6603 - accuracy: 0.9987 - val_loss: 1.8850 - val_accuracy: 0.8944 - lr: 1.8594e-05\n","Epoch 13/20\n","94/94 [==============================] - 14s 152ms/step - loss: 1.6099 - accuracy: 0.9967 - val_loss: 1.8254 - val_accuracy: 0.9009 - lr: 4.1095e-05\n","Epoch 14/20\n","94/94 [==============================] - 14s 153ms/step - loss: 1.5222 - accuracy: 0.9967 - val_loss: 2.1779 - val_accuracy: 0.7435 - lr: 6.8908e-05\n","Epoch 15/20\n","94/94 [==============================] - 14s 152ms/step - loss: 1.4181 - accuracy: 0.9967 - val_loss: 1.6854 - val_accuracy: 0.8685 - lr: 9.1408e-05\n","Epoch 16/20\n","94/94 [==============================] - 14s 154ms/step - loss: 1.3239 - accuracy: 0.9940 - val_loss: 2.4869 - val_accuracy: 0.6681 - lr: 1.0000e-04\n","Epoch 17/20\n","94/94 [==============================] - 14s 152ms/step - loss: 1.2445 - accuracy: 0.9920 - val_loss: 2.6533 - val_accuracy: 0.6185 - lr: 9.1402e-05\n","Epoch 18/20\n","94/94 [==============================] - 14s 152ms/step - loss: 1.1699 - accuracy: 0.9953 - val_loss: 2.4763 - val_accuracy: 0.6703 - lr: 6.8900e-05\n","Epoch 19/20\n","94/94 [==============================] - 14s 153ms/step - loss: 1.1244 - accuracy: 0.9953 - val_loss: 1.3689 - val_accuracy: 0.9052 - lr: 4.1089e-05\n","Epoch 20/20\n","94/94 [==============================] - 14s 153ms/step - loss: 1.1062 - accuracy: 0.9947 - val_loss: 1.2536 - val_accuracy: 0.9375 - lr: 1.8592e-05\n","Average Validation Accuracy: 0.7105603501200676\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"whTMwvWrTt6g"}},{"cell_type":"markdown","source":["## EffcientB7"],"metadata":{"id":"hJ67rAc3UHie"}},{"cell_type":"code","source":["from keras.applications.efficientnet import EfficientNetB7\n","from keras.models import Model\n","from keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping, LearningRateScheduler\n","import math\n","import numpy as np\n","\n","# EfficientNetB0 모델 로드 (최상위 층 제외)\n","base_model = EfficientNetB7(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","\n","# 모든 층을 훈련 가능하게 설정\n","for layer in base_model.layers:\n","    layer.trainable = True\n","\n","# 새로운 분류기 층 추가\n","x = base_model.output\n","x = GlobalAveragePooling2D()(x)\n","x = Dense(256, activation='relu')(x)\n","x = BatchNormalization()(x)\n","x = Dropout(0.5)(x)\n","predictions = Dense(1, activation='sigmoid')(x)\n","\n","# 새로운 모델 정의\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","# 옵티마이저 설정 (Adam 사용)\n","optimizer = Adam(learning_rate=0.0001)\n","\n","# 모델 컴파일\n","model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# 데이터 증강 없이 이미지 크기만 조정하는 ImageDataGenerator 설정\n","train_datagen = ImageDataGenerator(rescale=1./255)\n","validation_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# 데이터셋 로드 및 설정\n","train_generator = train_datagen.flow_from_directory(\n","    '/content/drive/MyDrive/DRUNK_DATA/LAYER3_TRAIN',\n","    target_size=(224, 224),\n","    batch_size=16,\n","    class_mode='binary')\n","\n","validation_generator = validation_datagen.flow_from_directory(\n","    '/content/drive/MyDrive/DRUNK_DATA/LAYER3_VALID',\n","    target_size=(224, 224),\n","    batch_size=16,\n","    class_mode='binary')\n","\n","# 코사인 니일링 웜업 스케줄러 함수 정의\n","def cosine_annealing_warmup(epoch, max_epoch=20, base_lr=0.0001, min_lr=0.00001):\n","    if epoch < 5:  # 웜업 기간 설정 (예: 처음 5 에포크)\n","        return base_lr * epoch / 5\n","    else:\n","        return min_lr + (base_lr - min_lr) * (1 + math.cos(math.pi * (epoch - 5) / (max_epoch - 5))) / 2\n","\n","# 코사인 니일링 웜업 스케줄러 콜백 생성\n","cosine_lr_scheduler = LearningRateScheduler(cosine_annealing_warmup)\n","\n","# 조기 중단 콜백 설정 (정확도 기반)\n","early_stopping = EarlyStopping(monitor='val_accuracy', mode='max', patience=10)\n","\n","# steps_per_epoch와 validation_steps 계산\n","steps_per_epoch = train_generator.samples // train_generator.batch_size\n","if train_generator.samples % train_generator.batch_size > 0:\n","    steps_per_epoch += 1\n","\n","validation_steps = validation_generator.samples // validation_generator.batch_size\n","if validation_generator.samples % validation_generator.batch_size > 0:\n","    validation_steps += 1\n","\n","# 모델 학습\n","history = model.fit(\n","    train_generator,\n","    steps_per_epoch=steps_per_epoch,\n","    epochs=20,\n","    validation_data=validation_generator,\n","    validation_steps=validation_steps,\n","    callbacks=[cosine_lr_scheduler, early_stopping])\n","\n","# 모델 저장\n","model.save('EfficientNetB7_drunk_or_sober.h5')\n","\n","# 각 epoch에서의 검증 정확도(val_accuracy) 리스트 가져오기\n","val_accuracies = history.history['val_accuracy']\n","\n","# 평균 검증 정확도 계산\n","average_val_accuracy = np.mean(val_accuracies)\n","\n","print(\"Average Validation Accuracy:\", average_val_accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Db2BB9lcULIP","executionInfo":{"status":"ok","timestamp":1700911072854,"user_tz":-540,"elapsed":1464407,"user":{"displayName":"표솔빈","userId":"04100473901833453355"}},"outputId":"7f0289e0-4d15-481b-a335-f04ac4869e40"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7_notop.h5\n","258076736/258076736 [==============================] - 9s 0us/step\n","Found 1502 images belonging to 2 classes.\n","Found 464 images belonging to 2 classes.\n","Epoch 1/20\n","94/94 [==============================] - 846s 8s/step - loss: 1.0791 - accuracy: 0.4794 - val_loss: 0.7389 - val_accuracy: 0.5000 - lr: 0.0000e+00\n","Epoch 2/20\n","94/94 [==============================] - 30s 321ms/step - loss: 0.6428 - accuracy: 0.6924 - val_loss: 0.7387 - val_accuracy: 0.5000 - lr: 2.0000e-05\n","Epoch 3/20\n","94/94 [==============================] - 30s 320ms/step - loss: 0.3076 - accuracy: 0.8569 - val_loss: 0.8353 - val_accuracy: 0.2909 - lr: 4.0000e-05\n","Epoch 4/20\n","94/94 [==============================] - 30s 320ms/step - loss: 0.1499 - accuracy: 0.9407 - val_loss: 0.6084 - val_accuracy: 0.7134 - lr: 6.0000e-05\n","Epoch 5/20\n","94/94 [==============================] - 30s 320ms/step - loss: 0.1030 - accuracy: 0.9647 - val_loss: 1.0524 - val_accuracy: 0.4720 - lr: 8.0000e-05\n","Epoch 6/20\n","94/94 [==============================] - 30s 320ms/step - loss: 0.0636 - accuracy: 0.9780 - val_loss: 1.1799 - val_accuracy: 0.5970 - lr: 1.0000e-04\n","Epoch 7/20\n","94/94 [==============================] - 30s 320ms/step - loss: 0.0319 - accuracy: 0.9913 - val_loss: 0.7648 - val_accuracy: 0.6681 - lr: 9.1405e-05\n","Epoch 8/20\n","94/94 [==============================] - 30s 320ms/step - loss: 0.0199 - accuracy: 0.9947 - val_loss: 0.5240 - val_accuracy: 0.7974 - lr: 6.8905e-05\n","Epoch 9/20\n","94/94 [==============================] - 30s 319ms/step - loss: 0.0164 - accuracy: 0.9947 - val_loss: 0.4558 - val_accuracy: 0.8254 - lr: 4.1093e-05\n","Epoch 10/20\n","94/94 [==============================] - 30s 320ms/step - loss: 0.0267 - accuracy: 0.9920 - val_loss: 0.3119 - val_accuracy: 0.8772 - lr: 1.8594e-05\n","Epoch 11/20\n","94/94 [==============================] - 30s 319ms/step - loss: 0.0150 - accuracy: 0.9947 - val_loss: 0.2716 - val_accuracy: 0.8922 - lr: 1.0000e-05\n","Epoch 12/20\n","94/94 [==============================] - 30s 320ms/step - loss: 0.0304 - accuracy: 0.9893 - val_loss: 0.2732 - val_accuracy: 0.8901 - lr: 1.8594e-05\n","Epoch 13/20\n","94/94 [==============================] - 30s 320ms/step - loss: 0.0321 - accuracy: 0.9893 - val_loss: 0.2359 - val_accuracy: 0.9116 - lr: 4.1095e-05\n","Epoch 14/20\n","94/94 [==============================] - 30s 320ms/step - loss: 0.0284 - accuracy: 0.9887 - val_loss: 0.8665 - val_accuracy: 0.7565 - lr: 6.8908e-05\n","Epoch 15/20\n","94/94 [==============================] - 30s 320ms/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 0.1370 - val_accuracy: 0.9440 - lr: 9.1408e-05\n","Epoch 16/20\n","94/94 [==============================] - 30s 320ms/step - loss: 0.0258 - accuracy: 0.9913 - val_loss: 0.6282 - val_accuracy: 0.7284 - lr: 1.0000e-04\n","Epoch 17/20\n","94/94 [==============================] - 30s 319ms/step - loss: 0.0408 - accuracy: 0.9854 - val_loss: 0.6334 - val_accuracy: 0.7759 - lr: 9.1402e-05\n","Epoch 18/20\n","94/94 [==============================] - 30s 319ms/step - loss: 0.0361 - accuracy: 0.9907 - val_loss: 0.6844 - val_accuracy: 0.7371 - lr: 6.8900e-05\n","Epoch 19/20\n","94/94 [==============================] - 30s 320ms/step - loss: 0.0249 - accuracy: 0.9927 - val_loss: 0.6430 - val_accuracy: 0.8147 - lr: 4.1089e-05\n","Epoch 20/20\n","94/94 [==============================] - 30s 320ms/step - loss: 0.0139 - accuracy: 0.9967 - val_loss: 0.2834 - val_accuracy: 0.9052 - lr: 1.8592e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]},{"output_type":"stream","name":"stdout","text":["Average Validation Accuracy: 0.729849137365818\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"TR_a4_oRUjLg"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuType":"V100","authorship_tag":"ABX9TyM1sJPFU95b7VH0aEPVpUwy"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}